Prediction Assignment
d2i2k

Friday, February 20, 2015

Question
How well did the six participants perform their weight lifting exercises based on pre-specified qualitative activity recognition classes?

Training and Testing Data
pml_training<-read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",na.strings=c("NA",""))
dim(pml_training) # 19622 rows, 160 cols
## [1] 19622   160
pml_testing<-read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",na.strings=c("NA",""))
dim(pml_testing)  # 20 rows, 160 cols
## [1]  20 160
Pre-Processing Steps
Step 1. Delete 100 columns with unavailable (NA) or missing (“”) data.
non_missing <- apply(!is.na(pml_training),2,sum)>19621
pml_training1 <- pml_training[,non_missing]
dim(pml_training1)  # 19,622 rows, 60 cols
## [1] 19622    60
non_missing <- apply(!is.na(pml_testing),2,sum)>19
pml_testing2 <- pml_testing[,non_missing]
dim(pml_testing2)  # 20 rows, 60 cols
## [1] 20 60
Step 2. Delete 406 rows in which the new_window variable equals “yes.”
pml_training2 <- subset(pml_training1,new_window=="no")
dim(pml_training2)  # 19,216 rows, 60 cols 
## [1] 19216    60
Step 3. Delete index, timestamps and new_window variable (Columns 1, 3-6). The remaining columns include 54 predictors and the classe variable.
pml_training2_user_name <- pml_training2[,2]
pml_training2_predictors <- pml_training2[7:60]
pml_training3 <- cbind(pml_training2_user_name,pml_training2_predictors)
dim(pml_training3) # 19,216 rows, 55 cols 
## [1] 19216    55
pml_testing2_user_name <- pml_testing2[,2]
pml_testing2_predictors <- pml_testing2[,7:60]
pml_testing3 <- cbind(pml_testing2_user_name,pml_testing2_predictors)
dim(pml_testing3) # 20 rows, 55 cols 
## [1] 20 55
library(caret)
## Warning: package 'caret' was built under R version 3.0.3
## Loading required package: lattice
## Warning: package 'lattice' was built under R version 3.0.3
## Loading required package: ggplot2
## Warning: package 'ggplot2' was built under R version 3.0.3
InTrain = createDataPartition(pml_training3$classe,p=0.4)[[1]]
training <- pml_training3[InTrain,] # 7689 rows, 55 cols
dim(training)
## [1] 7689   55
Algorithm
A random forest (rf) model was fitted to training data using the train function with five-fold cross validation (cv).

set.seed(125)
modFit<-train(classe~.,data=training,method="rf", trControl=trainControl(method="cv",number=5), prox=TRUE,allowParallel=TRUE)
## Loading required package: randomForest
## Warning: package 'randomForest' was built under R version 3.0.3
## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.
## Loading required namespace: e1071
print(modFit)
## Random Forest 
## 
## 7689 samples
##   54 predictor
##    5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## 
## Summary of sample sizes: 6149, 6154, 6151, 6150, 6152 
## 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy  Kappa   Accuracy SD  Kappa SD
##    2    0.9845    0.9804  0.002401     0.003038
##   30    0.9928    0.9910  0.002101     0.002658
##   58    0.9904    0.9878  0.001674     0.002117
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 30.
print(modFit$finalModel)
## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry, proximity = TRUE,      allowParallel = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 30
## 
##         OOB estimate of  error rate: 0.49%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 2188    1    0    0    0   0.0004568
## B    4 1479    5    0    0   0.0060484
## C    0    6 1331    4    0   0.0074571
## D    0    1   10 1248    0   0.0087371
## E    0    1    0    6 1405   0.0049575
Out-of-Sample Error (Cross-Validation)
Prediction
